{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "IuII0ZisP6b3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "bVQsEjlJSF-7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "z_dim = 100\n",
        "num_classes = 10\n",
        "img_size = 28\n",
        "channels = 1\n",
        "epochs = 50\n",
        "lr = 0.0002\n",
        "betal = 0.5\n",
        "\n",
        "os.makedirs(\"cgan_generated\", exist_ok=True)"
      ],
      "metadata": {
        "id": "BOsYI10gSZQY"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('.', train=True, download=True, transform=transform),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "20JuPTysSxGh"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim, num_classes, img_shape):\n",
        "        super().__init__()\n",
        "        self.label_emb = nn.Embedding(num_classes, num_classes)\n",
        "        self.img_shape = img_shape\n",
        "        input_dim = z_dim + num_classes\n",
        "\n",
        "        self.model = nn.Sequential(\n",
        "            nn.Linear(input_dim, 256),\n",
        "            nn.BatchNorm1d(256),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Linear(256, 512),\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Linear(512, 1024),\n",
        "            nn.BatchNorm1d(1024),\n",
        "            nn.ReLU(True),\n",
        "\n",
        "            nn.Linear(1024, int(torch.prod(torch.tensor(img_shape)))),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, noise, labels):\n",
        "      # Concatenate noise and label embedding\n",
        "      x = torch.cat([noise, self.label_emb(labels)], -1)\n",
        "      img = self.model(x)\n",
        "      img = img.view(x.size(0), *self.img_shape)\n",
        "      return img\n"
      ],
      "metadata": {
        "id": "koNWjCU_T1ZE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self, num_classes, img_shape):\n",
        "    super().__init__()\n",
        "    self.label_emb = nn.Embedding(num_classes, num_classes)\n",
        "    input_dim = int(torch.prod(torch.tensor(img_shape))) + num_classes\n",
        "\n",
        "    self.model = nn.Sequential(\n",
        "        nn.Linear(input_dim, 512),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        nn.Linear(512, 256),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        nn.Linear(256, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, img, labels):\n",
        "    # Flatten image and concatenate label\n",
        "    img_flate = img.view(img.size(0), -1)\n",
        "    x = torch.cat([img_flate, self.label_emb(labels)], dim=1)\n",
        "    return self.model(x)"
      ],
      "metadata": {
        "id": "xO_dnQ-xXp2H"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "img_shape = (channels, img_size, img_size)\n",
        "\n",
        "generator = Generator(z_dim, num_classes, img_shape).to(device)\n",
        "discriminator = Discriminator(num_classes, img_shape).to(device)\n",
        "\n",
        "criterion = nn.BCELoss()\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(betal, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(betal, 0.999))"
      ],
      "metadata": {
        "id": "3vGK0bNMYfbE"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 3 # Generator updates per iteration\n",
        "p = 1 # Discriminator updates per iteration"
      ],
      "metadata": {
        "id": "5ibAw2BlZ17v"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, epochs + 1):\n",
        "  for i, (real_imgs, real_labels) in enumerate(train_loader):\n",
        "    batch_size_curr = real_imgs.size(0)\n",
        "    real_imgs = real_imgs.to(device)\n",
        "    real_labels = real_labels.to(device)\n",
        "\n",
        "    real = torch.ones(batch_size_curr, 1, device=device)\n",
        "    fake = torch.zeros(batch_size_curr, 1, device=device)\n",
        "\n",
        "    ## Train Discriminator p times\n",
        "    for _ in range(p):\n",
        "      z = torch.randn(batch_size_curr, z_dim, device=device)\n",
        "      fake_labels = torch.randint(0, num_classes, (batch_size_curr,), device=device)\n",
        "\n",
        "      with torch.no_grad():\n",
        "        fake_imgs = generator(z, fake_labels)\n",
        "\n",
        "      # Real images\n",
        "      real_validity = discriminator(real_imgs, real_labels)\n",
        "      d_real_loss = criterion(real_validity, real)\n",
        "\n",
        "      # Fake images\n",
        "      fake_validity = discriminator(fake_imgs, fake_labels)\n",
        "      d_fake_loss = criterion(fake_validity, fake)\n",
        "\n",
        "      d_loss = d_real_loss + d_fake_loss\n",
        "\n",
        "      optimizer_D.zero_grad()\n",
        "      d_loss.backward()\n",
        "      optimizer_D.step()\n",
        "\n",
        "\n",
        "    ## Train Generator k times\n",
        "    for _ in range(k):\n",
        "      z = torch.randn(batch_size_curr, z_dim, device=device)\n",
        "      gen_labels = torch.randint(0, num_classes, (batch_size_curr,), device=device)\n",
        "      gen_imgs = generator(z, gen_labels)\n",
        "\n",
        "      # Try to full the discriminator\n",
        "      validity = discriminator(gen_imgs, gen_labels)\n",
        "      g_loss = criterion(validity, real)\n",
        "\n",
        "      optimizer_G.zero_grad()\n",
        "      g_loss.backward()\n",
        "      optimizer_G.step()\n",
        "\n",
        "    # Print progress\n",
        "    if i % 200 == 0:\n",
        "      print(f'[Epoch {epoch}/{epochs}] [Batch {i}/{len(train_loader)}] [D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]')\n",
        "\n",
        "    # Save example image afte each epoch\n",
        "    generator.eval()\n",
        "    with torch.no_grad():\n",
        "      z = torch.randn(10, z_dim, device=device)\n",
        "      labels = torch.arange(0, 10, dtype=torch.long, device=device)\n",
        "      samples = generator(z, labels)\n",
        "      samples = samples * 0.5 + 0.5  # Denormalize\n",
        "      save_image(samples, f'cgan_generated/epoch_{epoch}.png', nrow=10)\n",
        "    generator.train()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcvveX6fZ-DI",
        "outputId": "fce0019f-381c-4b63-a079-d6dc5ec8ed92"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1/50] [Batch 0/469] [D loss: 1.3255] [G loss: 0.6091]\n",
            "[Epoch 1/50] [Batch 200/469] [D loss: 1.4029] [G loss: 0.6220]\n",
            "[Epoch 1/50] [Batch 400/469] [D loss: 1.3976] [G loss: 0.6563]\n",
            "[Epoch 2/50] [Batch 0/469] [D loss: 1.3754] [G loss: 0.6693]\n",
            "[Epoch 2/50] [Batch 200/469] [D loss: 1.3672] [G loss: 0.7090]\n",
            "[Epoch 2/50] [Batch 400/469] [D loss: 1.4098] [G loss: 0.6814]\n",
            "[Epoch 3/50] [Batch 0/469] [D loss: 1.3763] [G loss: 0.7083]\n",
            "[Epoch 3/50] [Batch 200/469] [D loss: 1.4047] [G loss: 0.6685]\n",
            "[Epoch 3/50] [Batch 400/469] [D loss: 1.3768] [G loss: 0.7066]\n",
            "[Epoch 4/50] [Batch 0/469] [D loss: 1.3901] [G loss: 0.6906]\n",
            "[Epoch 4/50] [Batch 200/469] [D loss: 1.3834] [G loss: 0.6818]\n",
            "[Epoch 4/50] [Batch 400/469] [D loss: 1.3721] [G loss: 0.7274]\n",
            "[Epoch 5/50] [Batch 0/469] [D loss: 1.3974] [G loss: 0.6891]\n",
            "[Epoch 5/50] [Batch 200/469] [D loss: 1.3688] [G loss: 0.7032]\n",
            "[Epoch 5/50] [Batch 400/469] [D loss: 1.3909] [G loss: 0.7056]\n",
            "[Epoch 6/50] [Batch 0/469] [D loss: 1.3924] [G loss: 0.7163]\n",
            "[Epoch 6/50] [Batch 200/469] [D loss: 1.3424] [G loss: 0.7360]\n",
            "[Epoch 6/50] [Batch 400/469] [D loss: 1.3800] [G loss: 0.7013]\n",
            "[Epoch 7/50] [Batch 0/469] [D loss: 1.4041] [G loss: 0.6574]\n",
            "[Epoch 7/50] [Batch 200/469] [D loss: 1.3581] [G loss: 0.7153]\n",
            "[Epoch 7/50] [Batch 400/469] [D loss: 1.3504] [G loss: 0.9242]\n",
            "[Epoch 8/50] [Batch 0/469] [D loss: 1.3369] [G loss: 0.7142]\n",
            "[Epoch 8/50] [Batch 200/469] [D loss: 1.3938] [G loss: 0.6932]\n",
            "[Epoch 8/50] [Batch 400/469] [D loss: 1.3702] [G loss: 0.7079]\n",
            "[Epoch 9/50] [Batch 0/469] [D loss: 1.3453] [G loss: 0.7210]\n",
            "[Epoch 9/50] [Batch 200/469] [D loss: 1.3712] [G loss: 0.7102]\n",
            "[Epoch 9/50] [Batch 400/469] [D loss: 1.3823] [G loss: 0.7006]\n",
            "[Epoch 10/50] [Batch 0/469] [D loss: 1.4241] [G loss: 0.6815]\n",
            "[Epoch 10/50] [Batch 200/469] [D loss: 1.3394] [G loss: 0.7481]\n",
            "[Epoch 10/50] [Batch 400/469] [D loss: 1.4081] [G loss: 0.6767]\n",
            "[Epoch 11/50] [Batch 0/469] [D loss: 1.3831] [G loss: 0.6493]\n",
            "[Epoch 11/50] [Batch 200/469] [D loss: 1.4213] [G loss: 0.6819]\n",
            "[Epoch 11/50] [Batch 400/469] [D loss: 1.4261] [G loss: 0.6938]\n",
            "[Epoch 12/50] [Batch 0/469] [D loss: 1.3957] [G loss: 0.7204]\n",
            "[Epoch 12/50] [Batch 200/469] [D loss: 1.3490] [G loss: 0.7838]\n",
            "[Epoch 12/50] [Batch 400/469] [D loss: 1.3500] [G loss: 0.7665]\n",
            "[Epoch 13/50] [Batch 0/469] [D loss: 1.2364] [G loss: 0.7661]\n",
            "[Epoch 13/50] [Batch 200/469] [D loss: 1.3489] [G loss: 0.7273]\n",
            "[Epoch 13/50] [Batch 400/469] [D loss: 1.3427] [G loss: 0.7152]\n",
            "[Epoch 14/50] [Batch 0/469] [D loss: 1.2996] [G loss: 0.8604]\n",
            "[Epoch 14/50] [Batch 200/469] [D loss: 1.3416] [G loss: 0.8133]\n",
            "[Epoch 14/50] [Batch 400/469] [D loss: 1.2132] [G loss: 1.1962]\n",
            "[Epoch 15/50] [Batch 0/469] [D loss: 1.3058] [G loss: 0.8213]\n",
            "[Epoch 15/50] [Batch 200/469] [D loss: 1.3335] [G loss: 0.6805]\n",
            "[Epoch 15/50] [Batch 400/469] [D loss: 1.3237] [G loss: 0.7536]\n",
            "[Epoch 16/50] [Batch 0/469] [D loss: 1.3337] [G loss: 0.7803]\n",
            "[Epoch 16/50] [Batch 200/469] [D loss: 1.4009] [G loss: 0.7155]\n",
            "[Epoch 16/50] [Batch 400/469] [D loss: 1.3103] [G loss: 0.7626]\n",
            "[Epoch 17/50] [Batch 0/469] [D loss: 1.3122] [G loss: 0.8248]\n",
            "[Epoch 17/50] [Batch 200/469] [D loss: 1.2812] [G loss: 0.6584]\n",
            "[Epoch 17/50] [Batch 400/469] [D loss: 1.3314] [G loss: 0.7797]\n",
            "[Epoch 18/50] [Batch 0/469] [D loss: 1.2622] [G loss: 0.6172]\n",
            "[Epoch 18/50] [Batch 200/469] [D loss: 1.2956] [G loss: 0.8800]\n",
            "[Epoch 18/50] [Batch 400/469] [D loss: 1.2783] [G loss: 0.8702]\n",
            "[Epoch 19/50] [Batch 0/469] [D loss: 1.2632] [G loss: 0.7735]\n",
            "[Epoch 19/50] [Batch 200/469] [D loss: 1.3392] [G loss: 0.8438]\n",
            "[Epoch 19/50] [Batch 400/469] [D loss: 1.3269] [G loss: 0.6948]\n",
            "[Epoch 20/50] [Batch 0/469] [D loss: 1.3852] [G loss: 0.5650]\n",
            "[Epoch 20/50] [Batch 200/469] [D loss: 1.3116] [G loss: 0.7773]\n",
            "[Epoch 20/50] [Batch 400/469] [D loss: 1.2303] [G loss: 0.7005]\n",
            "[Epoch 21/50] [Batch 0/469] [D loss: 1.3523] [G loss: 0.8669]\n",
            "[Epoch 21/50] [Batch 200/469] [D loss: 1.2261] [G loss: 0.9458]\n",
            "[Epoch 21/50] [Batch 400/469] [D loss: 1.2662] [G loss: 0.7536]\n",
            "[Epoch 22/50] [Batch 0/469] [D loss: 1.2204] [G loss: 0.7788]\n",
            "[Epoch 22/50] [Batch 200/469] [D loss: 1.4229] [G loss: 0.8592]\n",
            "[Epoch 22/50] [Batch 400/469] [D loss: 1.2102] [G loss: 0.7268]\n",
            "[Epoch 23/50] [Batch 0/469] [D loss: 1.3107] [G loss: 0.9920]\n",
            "[Epoch 23/50] [Batch 200/469] [D loss: 1.3765] [G loss: 1.0458]\n",
            "[Epoch 23/50] [Batch 400/469] [D loss: 1.2963] [G loss: 0.9143]\n",
            "[Epoch 24/50] [Batch 0/469] [D loss: 1.3311] [G loss: 0.7126]\n",
            "[Epoch 24/50] [Batch 200/469] [D loss: 1.3945] [G loss: 0.8352]\n",
            "[Epoch 24/50] [Batch 400/469] [D loss: 1.2716] [G loss: 0.9823]\n",
            "[Epoch 25/50] [Batch 0/469] [D loss: 1.3705] [G loss: 0.7541]\n",
            "[Epoch 25/50] [Batch 200/469] [D loss: 1.3683] [G loss: 0.7689]\n",
            "[Epoch 25/50] [Batch 400/469] [D loss: 1.3365] [G loss: 0.6249]\n",
            "[Epoch 26/50] [Batch 0/469] [D loss: 1.2784] [G loss: 0.7509]\n",
            "[Epoch 26/50] [Batch 200/469] [D loss: 1.3171] [G loss: 0.5997]\n",
            "[Epoch 26/50] [Batch 400/469] [D loss: 1.4141] [G loss: 0.7160]\n",
            "[Epoch 27/50] [Batch 0/469] [D loss: 1.2864] [G loss: 0.7727]\n",
            "[Epoch 27/50] [Batch 200/469] [D loss: 1.3246] [G loss: 0.8351]\n",
            "[Epoch 27/50] [Batch 400/469] [D loss: 1.3406] [G loss: 0.7515]\n",
            "[Epoch 28/50] [Batch 0/469] [D loss: 1.3850] [G loss: 0.5787]\n",
            "[Epoch 28/50] [Batch 200/469] [D loss: 1.2907] [G loss: 0.8754]\n",
            "[Epoch 28/50] [Batch 400/469] [D loss: 1.3002] [G loss: 0.8472]\n",
            "[Epoch 29/50] [Batch 0/469] [D loss: 1.2869] [G loss: 0.7619]\n",
            "[Epoch 29/50] [Batch 200/469] [D loss: 1.2664] [G loss: 1.0289]\n",
            "[Epoch 29/50] [Batch 400/469] [D loss: 1.2916] [G loss: 1.2383]\n",
            "[Epoch 30/50] [Batch 0/469] [D loss: 1.3322] [G loss: 0.9612]\n",
            "[Epoch 30/50] [Batch 200/469] [D loss: 1.4559] [G loss: 0.5487]\n",
            "[Epoch 30/50] [Batch 400/469] [D loss: 1.4432] [G loss: 0.4713]\n",
            "[Epoch 31/50] [Batch 0/469] [D loss: 1.3647] [G loss: 0.8265]\n",
            "[Epoch 31/50] [Batch 200/469] [D loss: 1.3064] [G loss: 0.7952]\n",
            "[Epoch 31/50] [Batch 400/469] [D loss: 1.3892] [G loss: 0.7589]\n",
            "[Epoch 32/50] [Batch 0/469] [D loss: 1.3130] [G loss: 0.9012]\n",
            "[Epoch 32/50] [Batch 200/469] [D loss: 1.3498] [G loss: 0.6210]\n",
            "[Epoch 32/50] [Batch 400/469] [D loss: 1.2238] [G loss: 0.8368]\n",
            "[Epoch 33/50] [Batch 0/469] [D loss: 1.2005] [G loss: 1.0607]\n",
            "[Epoch 33/50] [Batch 200/469] [D loss: 1.2722] [G loss: 1.1880]\n",
            "[Epoch 33/50] [Batch 400/469] [D loss: 1.3078] [G loss: 0.8228]\n",
            "[Epoch 34/50] [Batch 0/469] [D loss: 1.3278] [G loss: 0.8546]\n",
            "[Epoch 34/50] [Batch 200/469] [D loss: 1.1405] [G loss: 0.6615]\n",
            "[Epoch 34/50] [Batch 400/469] [D loss: 1.2103] [G loss: 1.0373]\n",
            "[Epoch 35/50] [Batch 0/469] [D loss: 1.4389] [G loss: 0.8412]\n",
            "[Epoch 35/50] [Batch 200/469] [D loss: 1.2776] [G loss: 0.8823]\n",
            "[Epoch 35/50] [Batch 400/469] [D loss: 1.4290] [G loss: 0.6901]\n",
            "[Epoch 36/50] [Batch 0/469] [D loss: 1.3194] [G loss: 0.9361]\n",
            "[Epoch 36/50] [Batch 200/469] [D loss: 1.3567] [G loss: 0.7865]\n",
            "[Epoch 36/50] [Batch 400/469] [D loss: 1.2450] [G loss: 0.9864]\n",
            "[Epoch 37/50] [Batch 0/469] [D loss: 1.4229] [G loss: 1.1695]\n",
            "[Epoch 37/50] [Batch 200/469] [D loss: 1.2840] [G loss: 0.8378]\n",
            "[Epoch 37/50] [Batch 400/469] [D loss: 1.2095] [G loss: 0.8033]\n",
            "[Epoch 38/50] [Batch 0/469] [D loss: 1.2846] [G loss: 0.8098]\n",
            "[Epoch 38/50] [Batch 200/469] [D loss: 1.1491] [G loss: 0.9028]\n",
            "[Epoch 38/50] [Batch 400/469] [D loss: 1.2522] [G loss: 0.8990]\n",
            "[Epoch 39/50] [Batch 0/469] [D loss: 1.3142] [G loss: 0.7926]\n",
            "[Epoch 39/50] [Batch 200/469] [D loss: 1.2130] [G loss: 0.9136]\n",
            "[Epoch 39/50] [Batch 400/469] [D loss: 1.2069] [G loss: 0.9290]\n",
            "[Epoch 40/50] [Batch 0/469] [D loss: 1.1523] [G loss: 0.8601]\n",
            "[Epoch 40/50] [Batch 200/469] [D loss: 1.1448] [G loss: 0.6515]\n",
            "[Epoch 40/50] [Batch 400/469] [D loss: 1.2582] [G loss: 0.8405]\n",
            "[Epoch 41/50] [Batch 0/469] [D loss: 1.1816] [G loss: 0.9192]\n",
            "[Epoch 41/50] [Batch 200/469] [D loss: 1.2665] [G loss: 0.9046]\n",
            "[Epoch 41/50] [Batch 400/469] [D loss: 1.3468] [G loss: 0.9944]\n",
            "[Epoch 42/50] [Batch 0/469] [D loss: 1.2259] [G loss: 0.9919]\n",
            "[Epoch 42/50] [Batch 200/469] [D loss: 1.2534] [G loss: 1.0540]\n",
            "[Epoch 42/50] [Batch 400/469] [D loss: 1.3737] [G loss: 0.8653]\n",
            "[Epoch 43/50] [Batch 0/469] [D loss: 1.1033] [G loss: 1.0073]\n",
            "[Epoch 43/50] [Batch 200/469] [D loss: 1.2827] [G loss: 1.0402]\n",
            "[Epoch 43/50] [Batch 400/469] [D loss: 1.2625] [G loss: 0.7256]\n",
            "[Epoch 44/50] [Batch 0/469] [D loss: 1.3888] [G loss: 0.8693]\n",
            "[Epoch 44/50] [Batch 200/469] [D loss: 1.0965] [G loss: 0.8943]\n",
            "[Epoch 44/50] [Batch 400/469] [D loss: 1.1588] [G loss: 0.9038]\n",
            "[Epoch 45/50] [Batch 0/469] [D loss: 1.3411] [G loss: 1.1082]\n",
            "[Epoch 45/50] [Batch 200/469] [D loss: 1.2386] [G loss: 0.9834]\n",
            "[Epoch 45/50] [Batch 400/469] [D loss: 1.2760] [G loss: 0.7765]\n",
            "[Epoch 46/50] [Batch 0/469] [D loss: 1.1644] [G loss: 0.9728]\n",
            "[Epoch 46/50] [Batch 200/469] [D loss: 1.2651] [G loss: 1.0691]\n",
            "[Epoch 46/50] [Batch 400/469] [D loss: 1.2569] [G loss: 1.1629]\n",
            "[Epoch 47/50] [Batch 0/469] [D loss: 1.3292] [G loss: 0.9856]\n",
            "[Epoch 47/50] [Batch 200/469] [D loss: 1.3222] [G loss: 1.0016]\n",
            "[Epoch 47/50] [Batch 400/469] [D loss: 1.0404] [G loss: 0.9911]\n",
            "[Epoch 48/50] [Batch 0/469] [D loss: 1.1691] [G loss: 0.8695]\n",
            "[Epoch 48/50] [Batch 200/469] [D loss: 1.1951] [G loss: 0.9785]\n",
            "[Epoch 48/50] [Batch 400/469] [D loss: 1.2712] [G loss: 0.8306]\n",
            "[Epoch 49/50] [Batch 0/469] [D loss: 1.2545] [G loss: 0.8610]\n",
            "[Epoch 49/50] [Batch 200/469] [D loss: 1.3050] [G loss: 0.9000]\n",
            "[Epoch 49/50] [Batch 400/469] [D loss: 1.2244] [G loss: 0.8079]\n",
            "[Epoch 50/50] [Batch 0/469] [D loss: 1.3379] [G loss: 0.9337]\n",
            "[Epoch 50/50] [Batch 200/469] [D loss: 1.2086] [G loss: 1.0990]\n",
            "[Epoch 50/50] [Batch 400/469] [D loss: 1.2010] [G loss: 1.1539]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_digit_images(generator, digit, num_samples=16, save_path=None):\n",
        "  generator.eval()\n",
        "  z = torch.randn(num_samples, z_dim, device=device)\n",
        "  labels = torch.full((num_samples,), digit, device=device, dtype=torch.long)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    gen_images = generator(z, labels)\n",
        "    gen_images = gen_images * 0.5 + 0.5\n",
        "\n",
        "  if save_path:\n",
        "    save_image(gen_imgs, save_path, nrow=4)\n",
        "    print(f'Saved to {save_path}')\n",
        "  return gen_images"
      ],
      "metadata": {
        "id": "IpRN4IsEkY_G"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate 16 samples of digit 7\n",
        "generated_images = generate_digit_images(generator, digit=7, save_path='generated_digit_7.png')"
      ],
      "metadata": {
        "id": "hN4fjMS0lAf7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}