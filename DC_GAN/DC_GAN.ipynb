{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "https://docs.pytorch.org/tutorials/beginner/dcgan_faces_tutorial.html"
      ],
      "metadata": {
        "id": "yAWVfehckA8R"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6Q9nK_u-eu_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.utils import save_image, make_grid\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "z_dim = 100       # size of the noise vector\n",
        "image_size = 28\n",
        "channels = 1\n",
        "epochs = 50\n",
        "lr = 0.0002\n",
        "betal = 0.5       # adam optimizer betal\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Create output folder\n",
        "os.makedirs('generated_images', exist_ok=True)"
      ],
      "metadata": {
        "id": "XBmFpPml_ANE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize(image_size),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))   # Normalize between [-1, 1]\n",
        "])\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('.',train=True, download=True, transform=transform),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "_wEwMwyj_dgU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42029e17-b00d-45f1-a51d-c6ee4ce358f3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 11.5MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 344kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.20MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 5.69MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.Module):\n",
        "  def __init__(self, z_dim):\n",
        "    super(Generator, self).__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        # Input: (N, z_dim, 1, 1)\n",
        "        # Input: (input_dim (z), output_dim, kernel_size, stride, padding)\n",
        "        nn.ConvTranspose2d(z_dim, 256, 7, 1, 0, bias=False),\n",
        "        nn.BatchNorm2d(256),\n",
        "        nn.ReLU(True),\n",
        "        # Output: (N, 256, 7, 7),\n",
        "\n",
        "        nn.ConvTranspose2d(256, 128, 4, 2, 1, bias=False),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.ReLU(True),\n",
        "\n",
        "        nn.ConvTranspose2d(128, 1, 4, 2, 1, bias=False),\n",
        "        nn.Tanh()  # Output range [-1, 1]\n",
        "    )\n",
        "\n",
        "  def forward(self, z):\n",
        "    return self.net(z)"
      ],
      "metadata": {
        "id": "Pw4qZ5oE_deY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Discriminator, self).__init__()\n",
        "    self.net = nn.Sequential(\n",
        "        # Input: (N, 1, 28, 28)\n",
        "        nn.Conv2d(1, 64, 4, 2, 1, bias=False),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        nn.Conv2d(64, 128, 4, 2, 1, bias=False),\n",
        "        nn.BatchNorm2d(128),\n",
        "        nn.LeakyReLU(0.2, inplace=True),\n",
        "\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(128*7*7, 1),\n",
        "        nn.Sigmoid()\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    return self.net(x)"
      ],
      "metadata": {
        "id": "3JlpAgOC_dcp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = Generator(z_dim).to(device)\n",
        "discriminator = Discriminator().to(device)\n",
        "\n",
        "# Binary Cross Entropy Loss\n",
        "criterion = nn.BCELoss()\n",
        "\n",
        "# Optimizers\n",
        "optimizer_G = optim.Adam(generator.parameters(), lr=lr, betas=(betal, 0.999))\n",
        "optimizer_D = optim.Adam(discriminator.parameters(), lr=lr, betas=(betal, 0.999))"
      ],
      "metadata": {
        "id": "hvD5zuUI_dYZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_and_save_images(epoch):\n",
        "  generator.eval()\n",
        "  with torch.no_grad():\n",
        "    z = torch.randn(64, z_dim, 1, 1).to(device)\n",
        "    fake_images = generator(z)\n",
        "    fake_images = fake_images*0.5 + 0.5  # Denormalize to [0,1]\n",
        "    save_image(fake_images, f'generated_images/sample_epoch_{epoch}.png',nrow=8)\n",
        "  generator.train()"
      ],
      "metadata": {
        "id": "XFsOCW0r_dBV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 3 # Generator updates per iteration\n",
        "p = 1 # Discriminator updates per iteration"
      ],
      "metadata": {
        "id": "6r8TmMSOFSgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, epochs+1):\n",
        "  for i, (real_imgs, _) in enumerate(train_loader):\n",
        "    batch_size_curr = real_imgs.size(0)\n",
        "    real_imgs = real_imgs.to(device)\n",
        "\n",
        "    real = torch.ones(batch_size_curr, 1).to(device)\n",
        "    fake = torch.zeros(batch_size_curr, 1).to(device)\n",
        "\n",
        "    # Train Discriminator p times\n",
        "    for _ in range(p):\n",
        "      z = torch.randn(batch_size_curr, z_dim, 1, 1).to(device)\n",
        "      fake_imgs = generator(z)\n",
        "\n",
        "      # Real\n",
        "      real_validity = discriminator(real_imgs)\n",
        "      d_real_loss = criterion(real_validity, real)\n",
        "\n",
        "      # Fake\n",
        "      fake_validity = discriminator(fake_imgs.detach())\n",
        "      d_fake_loss = criterion(fake_validity, fake)\n",
        "\n",
        "      d_loss = d_real_loss + d_fake_loss\n",
        "\n",
        "      optimizer_D.zero_grad()\n",
        "      d_loss.backward()\n",
        "      optimizer_D.step()\n",
        "\n",
        "    # Train Generator k times\n",
        "    for _ in range(k):\n",
        "      z = torch.randn(batch_size_curr, z_dim, 1, 1).to(device)\n",
        "      fake_imgs = generator(z)\n",
        "\n",
        "      validity = discriminator(fake_imgs)\n",
        "      g_loss = criterion(validity, real)\n",
        "\n",
        "      optimizer_G.zero_grad()\n",
        "      g_loss.backward()\n",
        "      optimizer_G.step()\n",
        "\n",
        "    if i % 200 == 0:\n",
        "      print(f'[Epoch {epoch}/{epochs}] [Batch {i}/{len(train_loader)}] [D loss: {d_loss.item():.4f}] [G loss: {g_loss.item():.4f}]')\n",
        "\n",
        "  # Save sample images\n",
        "  generator.eval()\n",
        "  with torch.no_grad():\n",
        "      z = torch.randn(64, z_dim, 1, 1).to(device)\n",
        "      fake_images = generator(z)\n",
        "      fake_images = fake_images*0.5 + 0.5  # Denormalize to [0,1]\n",
        "      save_image(fake_images, f'generated_images/sample_epoch_{epoch}.png',nrow=8)\n",
        "  generator.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UiN__w76F0Mk",
        "outputId": "12faaeea-793d-4f5f-a0a6-0c2694e92b48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Epoch 1/50] [Batch 0/469] [D loss: 1.1729] [G loss: 0.6255]\n",
            "[Epoch 1/50] [Batch 200/469] [D loss: 1.1905] [G loss: 0.9280]\n",
            "[Epoch 1/50] [Batch 400/469] [D loss: 1.0978] [G loss: 1.3831]\n",
            "[Epoch 2/50] [Batch 0/469] [D loss: 1.2525] [G loss: 0.5058]\n",
            "[Epoch 2/50] [Batch 200/469] [D loss: 1.1411] [G loss: 1.1209]\n",
            "[Epoch 2/50] [Batch 400/469] [D loss: 1.1665] [G loss: 1.4688]\n",
            "[Epoch 3/50] [Batch 0/469] [D loss: 1.1059] [G loss: 1.0693]\n",
            "[Epoch 3/50] [Batch 200/469] [D loss: 1.1215] [G loss: 1.0138]\n",
            "[Epoch 3/50] [Batch 400/469] [D loss: 1.3277] [G loss: 1.3711]\n",
            "[Epoch 4/50] [Batch 0/469] [D loss: 1.1225] [G loss: 0.7394]\n",
            "[Epoch 4/50] [Batch 200/469] [D loss: 1.0722] [G loss: 0.7851]\n",
            "[Epoch 4/50] [Batch 400/469] [D loss: 1.0675] [G loss: 0.9508]\n",
            "[Epoch 5/50] [Batch 0/469] [D loss: 1.0146] [G loss: 1.2689]\n",
            "[Epoch 5/50] [Batch 200/469] [D loss: 1.0452] [G loss: 0.9317]\n",
            "[Epoch 5/50] [Batch 400/469] [D loss: 1.0425] [G loss: 0.7659]\n",
            "[Epoch 6/50] [Batch 0/469] [D loss: 1.1801] [G loss: 1.1874]\n",
            "[Epoch 6/50] [Batch 200/469] [D loss: 1.0354] [G loss: 0.7025]\n",
            "[Epoch 6/50] [Batch 400/469] [D loss: 1.1515] [G loss: 1.2206]\n",
            "[Epoch 7/50] [Batch 0/469] [D loss: 1.0766] [G loss: 1.0031]\n",
            "[Epoch 7/50] [Batch 200/469] [D loss: 1.0972] [G loss: 1.2211]\n",
            "[Epoch 7/50] [Batch 400/469] [D loss: 1.1056] [G loss: 1.1493]\n",
            "[Epoch 8/50] [Batch 0/469] [D loss: 1.5848] [G loss: 1.0345]\n",
            "[Epoch 8/50] [Batch 200/469] [D loss: 1.1565] [G loss: 1.2004]\n",
            "[Epoch 8/50] [Batch 400/469] [D loss: 1.0636] [G loss: 1.3824]\n",
            "[Epoch 9/50] [Batch 0/469] [D loss: 1.0696] [G loss: 0.9420]\n",
            "[Epoch 9/50] [Batch 200/469] [D loss: 1.1071] [G loss: 0.8424]\n",
            "[Epoch 9/50] [Batch 400/469] [D loss: 1.0945] [G loss: 0.9664]\n",
            "[Epoch 10/50] [Batch 0/469] [D loss: 1.1755] [G loss: 1.1762]\n",
            "[Epoch 10/50] [Batch 200/469] [D loss: 1.0996] [G loss: 0.7097]\n",
            "[Epoch 10/50] [Batch 400/469] [D loss: 1.2262] [G loss: 0.7875]\n",
            "[Epoch 11/50] [Batch 0/469] [D loss: 1.1540] [G loss: 1.1845]\n",
            "[Epoch 11/50] [Batch 200/469] [D loss: 1.0579] [G loss: 0.8956]\n",
            "[Epoch 11/50] [Batch 400/469] [D loss: 1.2118] [G loss: 1.1056]\n",
            "[Epoch 12/50] [Batch 0/469] [D loss: 1.2607] [G loss: 1.4723]\n",
            "[Epoch 12/50] [Batch 200/469] [D loss: 1.1976] [G loss: 1.6606]\n",
            "[Epoch 12/50] [Batch 400/469] [D loss: 1.2292] [G loss: 1.0409]\n",
            "[Epoch 13/50] [Batch 0/469] [D loss: 1.0940] [G loss: 1.2390]\n",
            "[Epoch 13/50] [Batch 200/469] [D loss: 1.1969] [G loss: 0.7516]\n",
            "[Epoch 13/50] [Batch 400/469] [D loss: 1.4391] [G loss: 0.5464]\n",
            "[Epoch 14/50] [Batch 0/469] [D loss: 1.1152] [G loss: 1.0533]\n",
            "[Epoch 14/50] [Batch 200/469] [D loss: 1.2639] [G loss: 1.5619]\n",
            "[Epoch 14/50] [Batch 400/469] [D loss: 1.1013] [G loss: 1.2167]\n",
            "[Epoch 15/50] [Batch 0/469] [D loss: 1.0270] [G loss: 0.9981]\n",
            "[Epoch 15/50] [Batch 200/469] [D loss: 1.1834] [G loss: 1.5660]\n",
            "[Epoch 15/50] [Batch 400/469] [D loss: 1.0392] [G loss: 0.9174]\n",
            "[Epoch 16/50] [Batch 0/469] [D loss: 1.0359] [G loss: 0.8468]\n",
            "[Epoch 16/50] [Batch 200/469] [D loss: 1.1627] [G loss: 0.9864]\n",
            "[Epoch 16/50] [Batch 400/469] [D loss: 1.0734] [G loss: 1.0124]\n",
            "[Epoch 17/50] [Batch 0/469] [D loss: 1.0937] [G loss: 1.0870]\n",
            "[Epoch 17/50] [Batch 200/469] [D loss: 1.2256] [G loss: 0.8791]\n",
            "[Epoch 17/50] [Batch 400/469] [D loss: 1.3312] [G loss: 0.4496]\n",
            "[Epoch 18/50] [Batch 0/469] [D loss: 1.0968] [G loss: 0.8779]\n",
            "[Epoch 18/50] [Batch 200/469] [D loss: 1.1578] [G loss: 0.9756]\n",
            "[Epoch 18/50] [Batch 400/469] [D loss: 1.1337] [G loss: 1.0663]\n",
            "[Epoch 19/50] [Batch 0/469] [D loss: 1.1665] [G loss: 0.7595]\n",
            "[Epoch 19/50] [Batch 200/469] [D loss: 1.1890] [G loss: 0.6573]\n",
            "[Epoch 19/50] [Batch 400/469] [D loss: 1.0325] [G loss: 1.1297]\n",
            "[Epoch 20/50] [Batch 0/469] [D loss: 1.1041] [G loss: 1.2085]\n",
            "[Epoch 20/50] [Batch 200/469] [D loss: 1.0872] [G loss: 1.1003]\n",
            "[Epoch 20/50] [Batch 400/469] [D loss: 1.0789] [G loss: 1.1418]\n",
            "[Epoch 21/50] [Batch 0/469] [D loss: 1.1313] [G loss: 0.7863]\n",
            "[Epoch 21/50] [Batch 200/469] [D loss: 1.1405] [G loss: 0.8626]\n",
            "[Epoch 21/50] [Batch 400/469] [D loss: 0.9994] [G loss: 0.9073]\n",
            "[Epoch 22/50] [Batch 0/469] [D loss: 1.0635] [G loss: 0.5971]\n",
            "[Epoch 22/50] [Batch 200/469] [D loss: 1.2098] [G loss: 0.9292]\n",
            "[Epoch 22/50] [Batch 400/469] [D loss: 1.1789] [G loss: 1.0761]\n",
            "[Epoch 23/50] [Batch 0/469] [D loss: 1.0966] [G loss: 0.7800]\n",
            "[Epoch 23/50] [Batch 200/469] [D loss: 1.2056] [G loss: 0.6410]\n",
            "[Epoch 23/50] [Batch 400/469] [D loss: 1.1925] [G loss: 1.1928]\n",
            "[Epoch 24/50] [Batch 0/469] [D loss: 1.0947] [G loss: 1.2127]\n",
            "[Epoch 24/50] [Batch 200/469] [D loss: 1.0032] [G loss: 0.9476]\n",
            "[Epoch 24/50] [Batch 400/469] [D loss: 1.0445] [G loss: 0.6952]\n",
            "[Epoch 25/50] [Batch 0/469] [D loss: 1.0252] [G loss: 1.2098]\n",
            "[Epoch 25/50] [Batch 200/469] [D loss: 1.2051] [G loss: 1.1228]\n",
            "[Epoch 25/50] [Batch 400/469] [D loss: 1.1536] [G loss: 0.7739]\n",
            "[Epoch 26/50] [Batch 0/469] [D loss: 1.0980] [G loss: 0.9762]\n",
            "[Epoch 26/50] [Batch 200/469] [D loss: 1.0665] [G loss: 1.3183]\n",
            "[Epoch 26/50] [Batch 400/469] [D loss: 1.0356] [G loss: 1.1677]\n",
            "[Epoch 27/50] [Batch 0/469] [D loss: 1.0492] [G loss: 1.0119]\n",
            "[Epoch 27/50] [Batch 200/469] [D loss: 1.0667] [G loss: 1.1199]\n",
            "[Epoch 27/50] [Batch 400/469] [D loss: 1.1991] [G loss: 0.7424]\n",
            "[Epoch 28/50] [Batch 0/469] [D loss: 1.1351] [G loss: 1.6627]\n",
            "[Epoch 28/50] [Batch 200/469] [D loss: 1.1349] [G loss: 0.9092]\n",
            "[Epoch 28/50] [Batch 400/469] [D loss: 1.1204] [G loss: 1.1902]\n",
            "[Epoch 29/50] [Batch 0/469] [D loss: 1.0453] [G loss: 1.2899]\n",
            "[Epoch 29/50] [Batch 200/469] [D loss: 1.1688] [G loss: 1.3535]\n",
            "[Epoch 29/50] [Batch 400/469] [D loss: 1.2474] [G loss: 0.8284]\n",
            "[Epoch 30/50] [Batch 0/469] [D loss: 1.3998] [G loss: 1.4344]\n",
            "[Epoch 30/50] [Batch 200/469] [D loss: 1.1595] [G loss: 1.0326]\n",
            "[Epoch 30/50] [Batch 400/469] [D loss: 1.0004] [G loss: 1.1544]\n",
            "[Epoch 31/50] [Batch 0/469] [D loss: 1.3239] [G loss: 0.5036]\n",
            "[Epoch 31/50] [Batch 200/469] [D loss: 1.0556] [G loss: 0.8851]\n",
            "[Epoch 31/50] [Batch 400/469] [D loss: 1.2520] [G loss: 1.4891]\n",
            "[Epoch 32/50] [Batch 0/469] [D loss: 1.0367] [G loss: 1.2047]\n",
            "[Epoch 32/50] [Batch 200/469] [D loss: 0.9728] [G loss: 0.9395]\n",
            "[Epoch 32/50] [Batch 400/469] [D loss: 1.1910] [G loss: 0.9827]\n",
            "[Epoch 33/50] [Batch 0/469] [D loss: 1.0459] [G loss: 0.9794]\n",
            "[Epoch 33/50] [Batch 200/469] [D loss: 1.0419] [G loss: 0.9177]\n",
            "[Epoch 33/50] [Batch 400/469] [D loss: 1.0795] [G loss: 1.1009]\n",
            "[Epoch 34/50] [Batch 0/469] [D loss: 1.0324] [G loss: 1.1053]\n",
            "[Epoch 34/50] [Batch 200/469] [D loss: 1.1504] [G loss: 0.6400]\n",
            "[Epoch 34/50] [Batch 400/469] [D loss: 1.1290] [G loss: 1.2161]\n",
            "[Epoch 35/50] [Batch 0/469] [D loss: 1.1535] [G loss: 0.9181]\n",
            "[Epoch 35/50] [Batch 200/469] [D loss: 1.3482] [G loss: 1.0783]\n",
            "[Epoch 35/50] [Batch 400/469] [D loss: 1.1209] [G loss: 1.1868]\n",
            "[Epoch 36/50] [Batch 0/469] [D loss: 1.2111] [G loss: 0.7872]\n",
            "[Epoch 36/50] [Batch 200/469] [D loss: 1.1275] [G loss: 0.9149]\n",
            "[Epoch 36/50] [Batch 400/469] [D loss: 1.0205] [G loss: 1.0434]\n",
            "[Epoch 37/50] [Batch 0/469] [D loss: 1.1421] [G loss: 0.9262]\n",
            "[Epoch 37/50] [Batch 200/469] [D loss: 1.0627] [G loss: 1.5216]\n",
            "[Epoch 37/50] [Batch 400/469] [D loss: 1.2671] [G loss: 1.5004]\n",
            "[Epoch 38/50] [Batch 0/469] [D loss: 1.0819] [G loss: 0.9250]\n",
            "[Epoch 38/50] [Batch 200/469] [D loss: 1.0441] [G loss: 0.8549]\n",
            "[Epoch 38/50] [Batch 400/469] [D loss: 1.3031] [G loss: 1.5202]\n",
            "[Epoch 39/50] [Batch 0/469] [D loss: 1.0134] [G loss: 1.0540]\n",
            "[Epoch 39/50] [Batch 200/469] [D loss: 1.1339] [G loss: 1.0730]\n",
            "[Epoch 39/50] [Batch 400/469] [D loss: 1.1762] [G loss: 1.6283]\n",
            "[Epoch 40/50] [Batch 0/469] [D loss: 1.0865] [G loss: 1.3474]\n",
            "[Epoch 40/50] [Batch 200/469] [D loss: 1.1583] [G loss: 1.1345]\n",
            "[Epoch 40/50] [Batch 400/469] [D loss: 0.9849] [G loss: 1.4347]\n",
            "[Epoch 41/50] [Batch 0/469] [D loss: 1.0837] [G loss: 0.9902]\n",
            "[Epoch 41/50] [Batch 200/469] [D loss: 1.1354] [G loss: 0.9661]\n",
            "[Epoch 41/50] [Batch 400/469] [D loss: 1.1443] [G loss: 0.9066]\n",
            "[Epoch 42/50] [Batch 0/469] [D loss: 1.0825] [G loss: 1.5454]\n",
            "[Epoch 42/50] [Batch 200/469] [D loss: 1.3053] [G loss: 1.4464]\n",
            "[Epoch 42/50] [Batch 400/469] [D loss: 1.2457] [G loss: 1.4121]\n",
            "[Epoch 43/50] [Batch 0/469] [D loss: 1.1219] [G loss: 0.9105]\n",
            "[Epoch 43/50] [Batch 200/469] [D loss: 1.1202] [G loss: 1.0093]\n",
            "[Epoch 43/50] [Batch 400/469] [D loss: 1.1527] [G loss: 0.8026]\n",
            "[Epoch 44/50] [Batch 0/469] [D loss: 1.1939] [G loss: 0.5646]\n",
            "[Epoch 44/50] [Batch 200/469] [D loss: 1.0181] [G loss: 0.8292]\n",
            "[Epoch 44/50] [Batch 400/469] [D loss: 1.2402] [G loss: 1.0505]\n",
            "[Epoch 45/50] [Batch 0/469] [D loss: 1.0591] [G loss: 1.0487]\n",
            "[Epoch 45/50] [Batch 200/469] [D loss: 1.1277] [G loss: 0.6545]\n",
            "[Epoch 45/50] [Batch 400/469] [D loss: 1.1511] [G loss: 1.2432]\n",
            "[Epoch 46/50] [Batch 0/469] [D loss: 1.2377] [G loss: 0.8806]\n",
            "[Epoch 46/50] [Batch 200/469] [D loss: 1.1102] [G loss: 1.1328]\n",
            "[Epoch 46/50] [Batch 400/469] [D loss: 1.1885] [G loss: 0.5737]\n",
            "[Epoch 47/50] [Batch 0/469] [D loss: 0.9941] [G loss: 0.8014]\n",
            "[Epoch 47/50] [Batch 200/469] [D loss: 1.0667] [G loss: 1.2098]\n",
            "[Epoch 47/50] [Batch 400/469] [D loss: 1.1809] [G loss: 0.4820]\n",
            "[Epoch 48/50] [Batch 0/469] [D loss: 1.0770] [G loss: 0.9228]\n",
            "[Epoch 48/50] [Batch 200/469] [D loss: 1.1675] [G loss: 0.6835]\n",
            "[Epoch 48/50] [Batch 400/469] [D loss: 0.9799] [G loss: 1.1915]\n",
            "[Epoch 49/50] [Batch 0/469] [D loss: 1.1240] [G loss: 1.5718]\n",
            "[Epoch 49/50] [Batch 200/469] [D loss: 1.0448] [G loss: 0.8762]\n",
            "[Epoch 49/50] [Batch 400/469] [D loss: 1.1730] [G loss: 0.9299]\n",
            "[Epoch 50/50] [Batch 0/469] [D loss: 1.1091] [G loss: 0.8156]\n",
            "[Epoch 50/50] [Batch 200/469] [D loss: 1.1292] [G loss: 1.0863]\n",
            "[Epoch 50/50] [Batch 400/469] [D loss: 1.0929] [G loss: 1.1638]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jcC4Ku38IHc1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}